id: https://open-and-sustainable.github.io/revaise-model/schema
name: revaise
description: "RevAIse â€” open standard for describing, sharing, and reproducing AI-supported systematic reviews, organized by stages."
prefixes:
  linkml: https://w3id.org/linkml/
  revaise: https://open-and-sustainable.github.io/revaise-model/schema/
default_prefix: revaise
imports:
  - linkml:types

# =========================
# ENUMS (workflow-first)
# =========================
enums:
  StageType:
    description: "Logical stages of a systematic review (typical flow)."
    permissible_values:
      scoping: {}
      registration: {}
      search: {}
      deduplication: {}
      screening_title_abstract: {}
      screening_fulltext: {}
      data_extraction: {}
      risk_of_bias: {}
      synthesis_meta_analysis: {}
      synthesis_narrative: {}
      reporting_prisma: {}
      reproducibility_pack: {}

  ArtifactKind:
    permissible_values:
      search_query: {}
      search_log: {}
      records_raw: {}
      records_deduped: {}
      screening_decisions: {}
      inclusion_list: {}
      exclusion_list: {}
      fulltexts: {}
      extraction_table: {}
      rob_table: {}
      meta_analysis_table: {}
      forest_plot: {}
      prisma_flow: {}
      code_archive: {}
      environment_lock: {}
      model_card: {}
      other: {}

  DatasetKind:
    permissible_values:
      bibliographic_db: {}
      local_index: {}
      fulltext_corpus: {}
      annotation_set: {}
      gold_labels: {}
      calibration_set: {}
      other: {}

  SynthesisType:
    permissible_values:
      meta_analysis: {}
      narrative: {}

  MetricKind:
    permissible_values:
      precision: {}
      recall: {}
      f1: {}
      accuracy: {}
      auroc: {}
      kappa: {}
      krippendorff_alpha: {}
      mpe: {}
      rmse: {}

  RoleKind:
    permissible_values:
      generator: {}
      classifier: {}
      ranker: {}
      deduper: {}
      extractor: {}
      summarizer: {}
      evidence_locator: {}
      critic: {}
      orchestrator: {}

  PromptRole:
    permissible_values:
      system: {}
      user: {}
      assistant: {}
      fewshot: {}

# =========================
# CLASSES (modular)
# =========================
classes:

  # --------- Root container ---------
  Review:
    description: "Top-level container of a systematic review, including registries for providers, models, prompts, and executed stages."
    slots:
      - id
      - title
      - protocol
      - providers
      - models
      - prompts
      - stages
      - artifacts
      - software_env
      - contributors
      - created_at
      - updated_at
    slot_usage:
      protocol: { range: Protocol }
      providers:
        range: Provider
        multivalued: true
      models:
        range: Model
        multivalued: true
      prompts:
        range: Prompt
        multivalued: true
      stages:
        range: StageExecution
        multivalued: true
      artifacts:
        range: Artifact
        multivalued: true
      software_env: { range: SoftwareEnv }
      contributors:
        range: Agent
        multivalued: true

  # --------- Protocol / scope ---------
  Protocol:
    description: "Scoping and registration details of the review."
    slots:
      - registry
      - registration_id
      - registration_url
      - research_question
      - eligibility_criteria
      - picos
      - start_date

  # --------- Stage execution ---------
  StageExecution:
    description: "Execution of a specific stage of the review, including AI use and outputs."
    slots:
      - stage_type
      - label
      - description
      - started_at
      - ended_at
      - inputs
      - datasets
      - ai_uses
      - human_in_loop
      - decisions
      - outputs
      - metrics
      - cost
    slot_usage:
      stage_type: { range: StageType }
      inputs:
        range: ArtifactRef
        multivalued: true
      datasets:
        range: DatasetRef
        multivalued: true
      ai_uses:
        range: AIUse
        multivalued: true
      human_in_loop: { range: HumanLoop }
      decisions:
        range: Decision
        multivalued: true
      outputs:
        range: Output
        multivalued: true
      metrics:
        range: Metric
        multivalued: true

  # --------- AI use (model + prompt) ---------
  AIUse:
    description: "Concrete use of AI within a stage: model, prompts, parameters, evaluation."
    slots:
      - role
      - task
      - model_id
      - provider_id
      - prompt_ids
      - parameters
      - tools_used
      - tool_calls
      - training_data
      - evaluation
      - safety_notes
      - seed
      - context_window
    slot_usage:
      role: { range: RoleKind }
      model_id: { range: string }
      provider_id: { range: string }
      prompt_ids:
        range: string
        multivalued: true
      parameters: { range: ModelParameters }
      tools_used:
        range: ToolRef
        multivalued: true
      tool_calls:
        range: ToolCall
        multivalued: true
      training_data: { range: DatasetRef }
      evaluation:
        range: Metric
        multivalued: true

  Provider:
    description: "Provider or service hosting an AI model."
    slots: [provider_id, name, url, terms_of_use]
    slot_usage:
      provider_id: {identifier: true}

  Model:
    description: "An AI model with unique identity, connected to a provider."
    slots: [model_id, name, version, provider_id, card_uri, modality, license]
    slot_usage:
      model_id: {identifier: true}
      provider_id: {range: string}

  Prompt:
    description: "Reusable prompt object."
    slots: [prompt_id, role, template, variables, rendered]
    slot_usage:
      prompt_id: {identifier: true}
      role: {range: PromptRole}

  # --------- Supporting objects ---------
  ModelParameters:
    description: "Generation or inference parameters."
    slots: [temperature, top_p, max_tokens, frequency_penalty, presence_penalty, stop]

  ToolRef:
    slots: [name, version, uri]

  ToolCall:
    slots: [tool_name, arguments_json, outputs_json, started_at, ended_at]

  DatasetRef:
    description: "External dataset reference."
    slots: [kind, name, uri, snapshot_hash, license, notes]
    slot_usage:
      kind: { range: DatasetKind }

  HumanLoop:
    description: "Human-in-the-loop setup for oversight and adjudication."
    slots: [policy, reviewers, adjudication_rules]
    slot_usage:
      reviewers:
        range: Agent
        multivalued: true

  Decision:
    description: "Atomic decision made on an item."
    slots: [item_id, action, rationale, agent, timestamp, overridden_by]
    slot_usage:
      agent: { range: Agent }

  Output:
    description: "Typed outputs of a stage."
    slots:
      - kind
      - artifacts
      - prisma
      - synthesis
    slot_usage:
      kind: { range: StageType }
      artifacts:
        range: ArtifactRef
        multivalued: true
      prisma: { range: PRISMAFlow }
      synthesis: { range: Synthesis }

  PRISMAFlow:
    description: "PRISMA flow counts."
    slots: [records_identified, duplicates_removed, records_screened,
            records_excluded, reports_sought, reports_not_retrieved,
            reports_assessed, studies_included, notes]

  Synthesis:
    description: "Meta-analysis or narrative synthesis output."
    slots: [synthesis_type, effect_model, effect_size, ci_low, ci_high,
            heterogeneity_i2, tau2, k_studies, subgroup_notes, narrative_summary]
    slot_usage:
      synthesis_type: { range: SynthesisType }

  Metric:
    description: "Evaluation metric."
    slots: [name, kind, value, split, threshold]
    slot_usage:
      kind: { range: MetricKind }

  Artifact:
    description: "Artifact stored in the review (files, datasets, code)."
    slots: [kind, uri, format, checksum, created_at]
    slot_usage:
      kind: { range: ArtifactKind }

  ArtifactRef:
    description: "Reference to an artifact in this or another RevAIse bundle."
    slots: [uri, checksum, label]

  SoftwareEnv:
    description: "Reproducible environment description."
    slots: [os, containers, lockfiles, hardware]
    slot_usage:
      containers:
        range: ArtifactRef
        multivalued: true
      lockfiles:
        range: ArtifactRef
        multivalued: true

  Agent:
    description: "Person or organization."
    slots: [name, orcid, email, role]

# =========================
# SLOTS
# =========================
slots:
  # Review
  id: {identifier: true, range: string}
  title: {range: string}
  protocol: {}
  providers: {}
  models: {}
  prompts: {}
  stages: {}
  artifacts: {}
  software_env: {}
  contributors: {}
  created_at: {range: datetime}
  updated_at: {range: datetime}

  # Protocol
  registry: {range: string}
  registration_id: {range: string}
  registration_url: {range: uri}
  research_question: {range: string}
  eligibility_criteria: {range: string}
  picos: {range: string}
  start_date: {range: date}

  # StageExecution
  stage_type: {}
  label: {range: string}
  description: {range: string}
  started_at: {range: datetime}
  ended_at: {range: datetime}
  inputs: {}
  datasets: {}
  ai_uses: {}
  human_in_loop: {}
  decisions: {}
  outputs: {}
  metrics: {}
  cost: {range: float}

  # AIUse
  role: {}
  task: {range: string}
  model_id: {range: string}
  provider_id: {range: string}
  prompt_ids: {}
  parameters: {}
  tools_used: {}
  tool_calls: {}
  training_data: {}
  evaluation: {}
  safety_notes: {range: string}
  seed: {range: integer}
  context_window: {range: integer}

  # Prompt
  prompt_id: {range: string}
  role: {}
  template: {range: string}
  variables: {range: string}
  rendered: {range: string}

  # ModelParameters
  temperature: {range: float}
  top_p: {range: float}
  max_tokens: {range: integer}
  frequency_penalty: {range: float}
  presence_penalty: {range: float}
  stop: {range: string}

  # ToolRef / ToolCall
  name: {range: string}
  version: {range: string}
  uri: {range: uri}
  tool_name: {range: string}
  arguments_json: {range: string}
  outputs_json: {range: string}
  started_at: {range: datetime}
  ended_at: {range: datetime}

  # DatasetRef
  kind: {}
  snapshot_hash: {range: string}
  license: {range: string}
  notes: {range: string}

  # HumanLoop
  policy: {range: string}
  reviewers: {}
  adjudication_rules: {range: string}

  # Decision
  item_id: {range: string}
  action: {range: string}
  rationale: {range: string}
  agent: {}
  timestamp: {range: datetime}
  overridden_by: {range: string}

  # Output
  kind: {}
  artifacts: {}
  prisma: {}
  synthesis: {}

  # PRISMA
  records_identified: {range: integer}
  duplicates_removed: {range: integer}
  records_screened: {range: integer}
  records_excluded: {range: integer}
  reports_sought: {range: integer}
  reports_not_retrieved: {range: integer}
  reports_assessed: {range: integer}
  studies_included: {range: integer}
  notes: {range: string}

  # Synthesis
  synthesis_type: {}
  effect_model: {range: string}
  effect_size: {range: float}
  ci_low: {range: float}
  ci_high: {range: float}
  heterogeneity_i2: {range: float}
  tau2: {range: float}
  k_studies: {range: integer}
  subgroup_notes: {range: string}
  narrative_summary: {range: string}

  # Metric
  name: {range: string}
  kind: {}
  value: {range: float}
  split: {range: string}
  threshold: {range: float}

  # Artifact
  format: {range: string}
  checksum: {range: string}

  # SoftwareEnv
  os: {range: string}
  containers: {}
  lockfiles: {}
  hardware: {range: string}

  # Agent
  orcid: {range: string}
  email: {range: string}
  role: {range: string}
